{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_table('dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d[d.isnull().values==True]\n",
    "d = d.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>g</th>\n",
       "      <th>mp</th>\n",
       "      <th>per</th>\n",
       "      <th>ts</th>\n",
       "      <th>3par</th>\n",
       "      <th>ftr</th>\n",
       "      <th>orb</th>\n",
       "      <th>...</th>\n",
       "      <th>ows</th>\n",
       "      <th>dws</th>\n",
       "      <th>ws</th>\n",
       "      <th>ws_48</th>\n",
       "      <th>obpm</th>\n",
       "      <th>dbpm</th>\n",
       "      <th>bpm</th>\n",
       "      <th>vorp</th>\n",
       "      <th>game_win</th>\n",
       "      <th>mvp_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>29</td>\n",
       "      <td>78</td>\n",
       "      <td>2867</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.449</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.254</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>2358</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.550</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.292</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                 player  age   g    mp   per     ts   3par    ftr  orb  \\\n",
       "0  2019           James Harden   29  78  2867  30.6  0.616  0.539  0.449  2.5   \n",
       "1  2019  Giannis Antetokounmpo   24  72  2358  30.9  0.644  0.163  0.550  7.3   \n",
       "\n",
       "     ...       ows  dws    ws  ws_48  obpm  dbpm   bpm  vorp  game_win  \\\n",
       "0    ...      11.4  3.8  15.2  0.254  10.5   1.1  11.7   9.9        53   \n",
       "1    ...       8.9  5.5  14.4  0.292   5.7   5.0  10.8   7.6        60   \n",
       "\n",
       "   mvp_label  \n",
       "0          1  \n",
       "1          1  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.read_table('2019MVP_pred.txt')\n",
    "b = b.fillna(0)\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = d.values[:,0]\n",
    "temp1 = b.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.reshape(temp, (-1,1))\n",
    "temp1 = np.reshape(temp1, (-1,1))\n",
    "a = np.hstack((temp, d.values[:,2:]))\n",
    "t = np.hstack((temp1, b.values[:,2:]))\n",
    "# t = np.hstack((temp1, b.values[:, 2:16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Normalizer().fit(a[:,1:25])\n",
    "new_a = transform.transform(a[:,1:25])\n",
    "transform = Normalizer().fit(t[:,1:25])\n",
    "new_t = transform.transform(t[:,1:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = np.hstack((a[:,0].reshape(-1,1), new_a))\n",
    "a = np.hstack((a_, a[:,25].reshape(-1,1)))\n",
    "a = np.hstack((a, d.values[:,-1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = np.hstack((t[:,0].reshape(-1,1), new_t))\n",
    "t = np.hstack((t_, t[:,25].reshape(-1,1)))\n",
    "t = np.hstack((t, b.values[:,-1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=([None, 25]), name='input')\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=([None,1]), name='mvp')\n",
    "\n",
    "class Helper():\n",
    "    \n",
    "    def __init__(self, data, test_data):\n",
    "        self.i = 0\n",
    "        self.all_train_batches = data\n",
    "        self.test_images = test_data[:,:25]\n",
    "        self.test_labels = test_data[:,25]\n",
    "    \n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "# def conv2d(x, W):\n",
    "#     return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# def max_pool_2by2(x):\n",
    "#     return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "#                           strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# def convolutional_layer(input_x, shape):\n",
    "#     W = init_weights(shape)\n",
    "#     b = init_bias([shape[3]])\n",
    "#     return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15059\n",
      "2\n",
      "Currently on step 0\n",
      "loss is:0.255795\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "loss is:0.005794\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "loss is:0.003573\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "loss is:0.002733\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "loss is:0.001846\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "loss is:0.000941\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "loss is:0.000519\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "loss is:0.000337\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "loss is:0.000238\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "loss is:0.000179\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "loss is:0.000139\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "loss is:0.000111\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "loss is:0.000091\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "loss is:0.000076\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "loss is:0.000064\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "loss is:0.000055\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "loss is:0.000047\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "loss is:0.000041\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "loss is:0.000036\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "loss is:0.000032\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "loss is:0.000028\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "loss is:0.000025\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "loss is:0.000023\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "loss is:0.000020\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "loss is:0.000019\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "loss is:0.000017\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "loss is:0.000015\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "loss is:0.000014\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "loss is:0.000013\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "loss is:0.000012\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "loss is:0.000011\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "loss is:0.000010\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "loss is:0.000009\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "loss is:0.000008\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "loss is:0.000008\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "loss is:0.000007\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "loss is:0.000007\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "loss is:0.000006\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "loss is:0.000006\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "loss is:0.000005\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "loss is:0.000005\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "loss is:0.000005\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "s = [0]*31\n",
    "sum_ = 0\n",
    "print(len(temp))\n",
    "for year in temp:\n",
    "    s[int(year)-1986] += 1\n",
    "for i in range(len(s)):\n",
    "    s[i] += sum_\n",
    "    sum_ = s[i]\n",
    "    \n",
    "tt = [0]*3\n",
    "sum_ = 0\n",
    "print(len(temp1))\n",
    "for year in temp1:\n",
    "    tt[int(year)-2017] += 1\n",
    "for i in range(len(tt)):\n",
    "    tt[i] += sum_\n",
    "    sum_ = tt[i]\n",
    "\n",
    "\n",
    "out1 = normal_full_layer(x,500)\n",
    "layer1 = tf.tanh(out1)\n",
    "\n",
    "out2 = normal_full_layer(layer1, 100)\n",
    "layer2 = tf.tanh(out2)\n",
    "\n",
    "out3 = normal_full_layer(layer2, 1)\n",
    "y_pred = tf.sigmoid(out3)\n",
    "\n",
    "mse = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_true,predictions=y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.00012)\n",
    "train = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(5000):\n",
    "        loopNum = i%20\n",
    "        if loopNum == 0:\n",
    "            _, loss, y_hat = sess.run([train,mse,y_pred], feed_dict={x: a[:s[loopNum], 1:26], y_true: a[:s[loopNum], 26].reshape(-1,1)})\n",
    "        else:\n",
    "            _, loss, y_hat = sess.run([train,mse, y_pred], feed_dict={x: a[s[loopNum-1]:s[loopNum], 1:26], y_true: a[s[loopNum-1]:s[loopNum], 26].reshape(-1,1)})\n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('loss is:{:f}'.format(loss))\n",
    "            # print(y_hat)\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            accuracy, y_hat2 = sess.run([acc,y_pred],feed_dict={x:t[:,1:26],y_true:t[:,26].reshape(-1,1)})\n",
    "            print('\\n')\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2019, 'Giannis Antetokounmpo'],\n",
       "       [2019, 'James Harden']], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.values[np.argpartition(y_hat2[:,0], -2)[-2:],0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98552716],\n",
       "       [ 0.98597878]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2[np.argpartition(y_hat2[:,0], -2)[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     for i in range(5000):\n",
    "#         loopNum = i%20\n",
    "#         sess.run(train, feed_dict={x: batch[0], y_true: batch[1]})\n",
    "        \n",
    "#         # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "#         if i%100 == 0:\n",
    "            \n",
    "#             print('Currently on step {}'.format(i))\n",
    "#             print('Accuracy is:')\n",
    "#             # Test the Train Model\n",
    "#             matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "\n",
    "#             acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "#             print(sess.run(acc,feed_dict={x:,y_true:ch.test_labels,hold_prob:1.0}))\n",
    "#             print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 NBA MVP predicted by the model: James Harden\n"
     ]
    }
   ],
   "source": [
    "print(\"2019 NBA MVP predicted by the model: \" + b.values[np.argmax(y_hat2),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tfdeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
