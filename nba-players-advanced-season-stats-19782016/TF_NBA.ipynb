{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_table('dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d[d.isnull().values==True]\n",
    "d = d.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>mp</th>\n",
       "      <th>per</th>\n",
       "      <th>ts</th>\n",
       "      <th>3par</th>\n",
       "      <th>ftr</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>...</th>\n",
       "      <th>ows</th>\n",
       "      <th>dws</th>\n",
       "      <th>ws</th>\n",
       "      <th>ws_48</th>\n",
       "      <th>obpm</th>\n",
       "      <th>dbpm</th>\n",
       "      <th>bpm</th>\n",
       "      <th>vorp</th>\n",
       "      <th>game_win</th>\n",
       "      <th>mvp_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taurean Waller-Prince</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>981</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.330</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Thabo Sefolosha</td>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "      <td>1596</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.190</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mike Scott</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.136</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Dennis Schroder</td>\n",
       "      <td>23</td>\n",
       "      <td>79</td>\n",
       "      <td>2485</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>Lamar Patterson</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-11.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                 player  age  mp   per    ts   3par    ftr    orb  drb  \\\n",
       "0  2017  Taurean Waller-Prince   22  59   981   9.8  0.513  0.358  0.330  2.8   \n",
       "1  2017        Thabo Sefolosha   32  62  1596  11.9  0.519  0.304  0.190  3.8   \n",
       "2  2017             Mike Scott   28  18   195   5.9  0.360  0.458  0.136  5.7   \n",
       "3  2017        Dennis Schroder   23  79  2485  16.1  0.533  0.242  0.210  1.9   \n",
       "4  2017        Lamar Patterson   25   5    40  -1.9  0.276  0.400  0.200  2.8   \n",
       "\n",
       "     ...      ows  dws   ws  ws_48  obpm  dbpm   bpm  vorp  game_win  \\\n",
       "0    ...     -0.4  1.5  1.1  0.054  -3.8   1.5  -2.3  -0.1        50   \n",
       "1    ...      0.6  2.7  3.3  0.098  -1.9   3.1   1.2   1.3        50   \n",
       "2    ...     -0.3  0.2 -0.1 -0.014  -5.3  -0.1  -5.3  -0.2        50   \n",
       "3    ...      1.2  2.5  3.7  0.071   0.7  -1.4  -0.7   0.8        50   \n",
       "4    ...     -0.2  0.0 -0.1 -0.176  -9.9  -1.2 -11.2  -0.1        50   \n",
       "\n",
       "   mvp_label  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.read_table('testset.txt')\n",
    "b = b.fillna(0)\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = d.values[:,0]\n",
    "temp1 = b.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.reshape(temp, (-1,1))\n",
    "temp1 = np.reshape(temp1, (-1,1))\n",
    "a = np.hstack((temp, d.values[:,2:]))\n",
    "t = np.hstack((temp1, b.values[:,2:]))\n",
    "# t = np.hstack((temp1, b.values[:, 2:16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Normalizer().fit(a[:,1:25])\n",
    "new_a = transform.transform(a[:,1:25])\n",
    "transform = Normalizer().fit(t[:,1:25])\n",
    "new_t = transform.transform(t[:,1:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = np.hstack((a[:,0].reshape(-1,1), new_a))\n",
    "a = np.hstack((a_, a[:,25].reshape(-1,1)))\n",
    "a = np.hstack((a, d.values[:,-1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = np.hstack((t[:,0].reshape(-1,1), new_t))\n",
    "t = np.hstack((t_, t[:,25].reshape(-1,1)))\n",
    "t = np.hstack((t, b.values[:,-1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=([None, 25]), name='input')\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=([None,1]), name='mvp')\n",
    "\n",
    "class Helper():\n",
    "    \n",
    "    def __init__(self, data, test_data):\n",
    "        self.i = 0\n",
    "        self.all_train_batches = data\n",
    "        self.test_images = test_data[:,:25]\n",
    "        self.test_labels = test_data[:,25]\n",
    "    \n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "# def conv2d(x, W):\n",
    "#     return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# def max_pool_2by2(x):\n",
    "#     return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "#                           strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# def convolutional_layer(input_x, shape):\n",
    "#     W = init_weights(shape)\n",
    "#     b = init_bias([shape[3]])\n",
    "#     return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15059\n",
      "1547\n",
      "Currently on step 0\n",
      "loss is:0.174851\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "loss is:0.005453\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "loss is:0.003448\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "loss is:0.002716\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "loss is:0.001938\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "loss is:0.000996\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "loss is:0.000518\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "loss is:0.000325\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "loss is:0.000227\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "loss is:0.000169\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "loss is:0.000131\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "loss is:0.000105\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "loss is:0.000086\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "loss is:0.000071\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "loss is:0.000060\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "loss is:0.000052\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "loss is:0.000045\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "loss is:0.000039\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "loss is:0.000034\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "loss is:0.000030\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "loss is:0.000027\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "loss is:0.000024\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "loss is:0.000022\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "loss is:0.000020\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "loss is:0.000018\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "loss is:0.000016\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "loss is:0.000015\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "loss is:0.000013\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "loss is:0.000012\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "loss is:0.000011\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "loss is:0.000010\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "loss is:0.000010\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "loss is:0.000009\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "loss is:0.000008\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "loss is:0.000008\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "loss is:0.000007\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "loss is:0.000007\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "loss is:0.000006\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "loss is:0.000006\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "loss is:0.000005\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "loss is:0.000005\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "loss is:0.000005\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "loss is:0.000004\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "loss is:0.000003\n",
      "\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "s = [0]*31\n",
    "sum_ = 0\n",
    "print(len(temp))\n",
    "for year in temp:\n",
    "    s[int(year)-1986] += 1\n",
    "for i in range(len(s)):\n",
    "    s[i] += sum_\n",
    "    sum_ = s[i]\n",
    "    \n",
    "tt = [0]*3\n",
    "sum_ = 0\n",
    "print(len(temp1))\n",
    "for year in temp1:\n",
    "    tt[int(year)-2017] += 1\n",
    "for i in range(len(tt)):\n",
    "    tt[i] += sum_\n",
    "    sum_ = tt[i]\n",
    "\n",
    "\n",
    "out1 = normal_full_layer(x,500)\n",
    "layer1 = tf.tanh(out1)\n",
    "\n",
    "out2 = normal_full_layer(layer1, 100)\n",
    "layer2 = tf.tanh(out2)\n",
    "\n",
    "out3 = normal_full_layer(layer2, 1)\n",
    "y_pred = tf.sigmoid(out3)\n",
    "\n",
    "mse = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_true,predictions=y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.00012)\n",
    "train = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(5000):\n",
    "        loopNum = i%20\n",
    "        if loopNum == 0:\n",
    "            _, loss, y_hat = sess.run([train,mse,y_pred], feed_dict={x: a[:s[loopNum], 1:26], y_true: a[:s[loopNum], 26].reshape(-1,1)})\n",
    "        else:\n",
    "            _, loss, y_hat = sess.run([train,mse, y_pred], feed_dict={x: a[s[loopNum-1]:s[loopNum], 1:26], y_true: a[s[loopNum-1]:s[loopNum], 26].reshape(-1,1)})\n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('loss is:{:f}'.format(loss))\n",
    "            # print(y_hat)\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            accuracy, y_hat2 = sess.run([acc,y_pred],feed_dict={x:t[:,1:26],y_true:t[:,26].reshape(-1,1)})\n",
    "            print('\\n')\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2018, 'Naz Mitrou-Long'],\n",
       "       [2019, 'James Harden'],\n",
       "       [2018, 'James Harden'],\n",
       "       [2019, 'Giannis Antetokounmpo'],\n",
       "       [2017, 'Russell Westbrook']], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.values[np.argpartition(y_hat2[:,0], -5)[-5:],0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00402026],\n",
       "       [ 0.18727021],\n",
       "       [ 0.9859497 ],\n",
       "       [ 0.18131027],\n",
       "       [ 0.98605448]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2[np.argpartition(y_hat2[:,0], -5)[-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     for i in range(5000):\n",
    "#         loopNum = i%20\n",
    "#         sess.run(train, feed_dict={x: batch[0], y_true: batch[1]})\n",
    "        \n",
    "#         # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "#         if i%100 == 0:\n",
    "            \n",
    "#             print('Currently on step {}'.format(i))\n",
    "#             print('Accuracy is:')\n",
    "#             # Test the Train Model\n",
    "#             matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "\n",
    "#             acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "#             print(sess.run(acc,feed_dict={x:,y_true:ch.test_labels,hold_prob:1.0}))\n",
    "#             print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tfdeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
